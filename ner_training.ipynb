{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1654525-9493-40e8-98a6-6f037bc2a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - Loss: {'ner': np.float32(0.000119165765)}\n",
      "Iteration 2 - Loss: {'ner': np.float32(2.9391562e-05)}\n",
      "Iteration 3 - Loss: {'ner': np.float32(1.1079147e-08)}\n",
      "Iteration 4 - Loss: {'ner': np.float32(9.178846e-10)}\n",
      "Iteration 5 - Loss: {'ner': np.float32(6.629118e-10)}\n",
      "Iteration 6 - Loss: {'ner': np.float32(1.2201489e-11)}\n",
      "Iteration 7 - Loss: {'ner': np.float32(8.052201e-09)}\n",
      "Iteration 8 - Loss: {'ner': np.float32(2.4308002e-13)}\n",
      "Iteration 9 - Loss: {'ner': np.float32(1.8959153e-13)}\n",
      "Iteration 10 - Loss: {'ner': np.float32(1.8166048e-12)}\n",
      "Iteration 11 - Loss: {'ner': np.float32(1.2427228e-13)}\n",
      "Iteration 12 - Loss: {'ner': np.float32(1.5585518e-14)}\n",
      "Iteration 13 - Loss: {'ner': np.float32(6.1087354e-16)}\n",
      "Iteration 14 - Loss: {'ner': np.float32(4.3761846e-16)}\n",
      "Iteration 15 - Loss: {'ner': np.float32(2.3060576e-13)}\n",
      "Iteration 16 - Loss: {'ner': np.float32(1.4642634e-11)}\n",
      "Iteration 17 - Loss: {'ner': np.float32(7.748246e-15)}\n",
      "Iteration 18 - Loss: {'ner': np.float32(9.072163e-14)}\n",
      "Iteration 19 - Loss: {'ner': np.float32(1.0070245e-14)}\n",
      "Iteration 20 - Loss: {'ner': np.float32(1.0885226e-15)}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Load small model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load data\n",
    "with open(\"train_data_spacy.json\", \"r\") as f:\n",
    "    TRAIN_DATA = json.load(f)\n",
    "\n",
    "# Get the NER pipe\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Add new labels\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Disable other pipes during training\n",
    "pipe_exceptions = [\"ner\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "# Training\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(20):  # number of iterations\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update([example], drop=0.3, losses=losses)\n",
    "        print(f\"Iteration {itn+1} - Loss: {losses}\")\n",
    "\n",
    "# Save the model\n",
    "nlp.to_disk(\"ner_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ca7e3a7-de4e-47bc-82c8-396e766e4be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Confidentiality       1.00      1.00      1.00         1\n",
      "    Termination       0.00      0.00      0.00         1\n",
      "\n",
      "      micro avg       1.00      0.50      0.67         2\n",
      "      macro avg       0.50      0.50      0.50         2\n",
      "   weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0d4fc1-f80d-4bec-bc42-d848bcc2082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: train_data_spacy.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Minimal dummy training data – update with real data later\n",
    "train_data = [\n",
    "    (\"This agreement includes a confidentiality clause.\", {\"entities\": [(29, 44, \"Confidentiality\")]}),\n",
    "    (\"The contract may be terminated at any time by either party.\", {\"entities\": [(23, 33, \"Termination\")]}),\n",
    "]\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"train_data_spacy.json\", \"w\") as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "print(\"✓ Saved: train_data_spacy.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d2673-d0ad-47d8-9890-dd9e29d97fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Legal Contract Analyzer",
   "language": "python",
   "name": "legal-contract-analyzer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
